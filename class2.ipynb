{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Q2jmJVEqAZb8qmo9J6UM82-Rg395SD90",
      "authorship_tag": "ABX9TyO4lDhm+IMLJIAm6vLsq73d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/good-thinking/easy-coding2/blob/main/class2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.metrics import mean_squared_error \n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "\n",
        "from scipy.stats.distributions import chi_gen\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.metrics import Accuracy\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n"
      ],
      "metadata": {
        "id": "a8cWY6EXtGsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tRYkjycd9lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z8WNpx4s9Qa"
      },
      "outputs": [],
      "source": [
        "class numeric :\n",
        "  def __init__(self):\n",
        "    self.df = 0\n",
        "    self.data_IQR2 = 0\n",
        "    self.train_test_data = 0\n",
        "    self.Y_value = 0\n",
        "    self.Y_test = 0\n",
        "  \n",
        "  def read_file(self, file_address) :\n",
        "    print(\"file read\")\n",
        "    self.df = pd.read_csv(file_address, encoding = \"cp949\")\n",
        "  \n",
        "  def normalization(self, column_number):\n",
        "#sns.distplot(self.df[self.df.columns[column_number]])\n",
        "    print(\"normalization\")\n",
        "    self.df[self.df.columns[column_number]] = np.log1p(self.df[self.df.columns[column_number]])\n",
        "    sns.distplot(self.df[self.df.columns[column_number]])\n",
        "\n",
        "  def data_IQR(self, column_number) :\n",
        "    print(\"-------------- Data_IQR ---------------\")\n",
        "    q1 = self.df[self.df.columns[column_number]].quantile(q=0.25)\n",
        "    q3 = self.df[self.df.columns[column_number]].quantile(q=0.75)\n",
        "    IQR = q3-q1\n",
        "    self.data_IQR2 = self.df[(self.df[self.df.columns[column_number]] < q3 + IQR * 1.5) & \n",
        "                 (self.df[self.df.columns[column_number]] > q1 - IQR * 1.5)]\n",
        "    sns.distplot(self.df[self.df.columns[column_number]])\n",
        "    self.df = self.data_IQR2\n",
        "\n",
        "  def before_making_model(self, X_list,Y_list,column_number):\n",
        "    num = X_list\n",
        "    cg = Y_list\n",
        "    X = self.df[num+cg]\n",
        "    Y = self.df[self.df.columns[column_number]]\n",
        "    ct = ColumnTransformer([(\"scaling\", StandardScaler(), num), \n",
        "                        (\"onehot\", OneHotEncoder(sparse = False), cg)])\n",
        "    X_train, X_test, Y_train, self.Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "   \n",
        "    ct.fit(X_train)\n",
        "    X_train = ct.transform(X_train)\n",
        "    X_test = ct.transform(X_test)\n",
        "    self.train_test_data = [X_train, X_test, Y_train, self.Y_test]\n",
        "  \n",
        "  def before_making_model2(self, X_list,Y_list,column_number,confirm):\n",
        "    num = X_list\n",
        "    cg = Y_list\n",
        "    X = self.df[num+cg]\n",
        "    Y = self.df[self.df.columns[column_number]]\n",
        "    X_train, X_test, Y_train, self.Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "    self.train_test_data = [X_train, X_test, Y_train, self.Y_test]\n",
        "\n",
        "  def linearRegress(self, train_test_data,columns):\n",
        "    print(\"----------LinearRegression value-----------\")\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    lr = LinearRegression().fit(X_train, Y_train) \n",
        "    Y_pred = lr.predict(X_test)\n",
        "    print(\"predict value\\n\",Y_pred)\n",
        "    print(\"[linear]\")\n",
        "    print(\"train R2 : {:.3f}\".format(lr.score(X_train, Y_train)))\n",
        "    print(\"test R2 : {:.3f}\".format(lr.score(X_test, self.Y_test))) \n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred)) \n",
        "    print(\"RMSE : {:.3f}\". format(rmse)) \n",
        "    print(columns)\n",
        "    print(\"절편\", np.round(lr.intercept_, 3))\n",
        "    print(\"가중치(beta)\", np.round(lr.coef_, 3))\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def Reset_index(self, Y_test,column_number):\n",
        "    self.Y_test = (pd.DataFrame(self.Y_test)).reset_index()\n",
        "    self.Y_test = pd.DataFrame(self.Y_test[self.Y_test.columns[column_number]])\n",
        "  \n",
        "  def plot_picture(self, Y_pred,Y_test):\n",
        "    print(\"----------- plot grow----------- \")\n",
        "    %matplotlib Inline\n",
        "    plt.plot(Y_pred)\n",
        "    plt.plot(self.Y_test)\n",
        "\n",
        "  def Ridge_function(self,train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    lr_ridge = Ridge(random_state = 0).fit(X_train, Y_train)\n",
        "    Y_pred = lr_ridge.predict(X_test)\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"[ridge]\")\n",
        "    print(\"ridge R2 : {:.3f}\".format(lr_ridge.score(X_train, Y_train)))\n",
        "    print(\"RMSE : {:.3f}\".format(rmse))\n",
        "    print(\"절편\", np.round(lr_ridge.intercept_, 3))\n",
        "    print(\"가중치(beta)\", np.round(lr_ridge.coef_, 3))\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def Lasso_function(self, train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    lr_lasso = Lasso(random_state = 0, alpha = 0.01, max_iter = 1000).fit(X_train, Y_train)\n",
        "    Y_pred = lr_lasso.predict(X_test)\n",
        "\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"[lasso]\")\n",
        "    print(\"lasso R2 : {:.3f}\".format(lr_lasso.score(X_train, Y_train)))\n",
        "    print(\"RMSE : {:.3f}\".format(rmse))\n",
        "    print(\"절편\", np.round(lr_lasso.intercept_, 3))\n",
        "    print(\"가중치(beta)\", np.round(lr_lasso.coef_, 3))\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def Elastic_function(self,train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    lr_ela = ElasticNet(alpha = 0.01).fit(X_train, Y_train)\n",
        "    Y_pred = lr_ela.predict(X_test)\n",
        "\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"[elastic]\")\n",
        "    print(\"ela R2 : {:.3f}\".format(lr_ela.score(X_train, Y_train)))\n",
        "    print(\"RMSE : {:.3f}\".format(rmse))\n",
        "    print(\"절편\", np.round(lr_ela.intercept_, 3))\n",
        "    print(\"가중치(beta)\", np.round(lr_ela.coef_, 3))\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "  \n",
        "  def knn_reg_function(self,train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    knn_reg = KNeighborsRegressor(n_neighbors=9, p =2)\n",
        "    knn_reg.fit(X_train, Y_train)\n",
        "    Y_pred = knn_reg.predict(X_test)\n",
        "    print(\"[knn neighbors]\")\n",
        "    print(\"accuracy: {:.3f}\".format(knn_reg.score(X_train, Y_train)))\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"RMSE: {:.3f}\".format(rmse))\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def decision_tree(self, train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    DT_model_reg = DecisionTreeRegressor(random_state = 0, max_depth = 5)\n",
        "    DT_model_reg.fit(X_train, Y_train)\n",
        "    Y_pred = DT_model_reg.predict(X_test)\n",
        "    print(\"[decision_tree]\")\n",
        "    print(\"accuracy : {:.3f}\".format(DT_model_reg.score(X_train, Y_train)))\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"rmse :  {:.3f}\".format(rmse))\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "    \n",
        "    return[X_train, DT_model_reg]\n",
        "\n",
        "  def SVR_function(self, train_test_data):\n",
        "   X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "   SVR_model = SVR(C=1, kernel = \"linear\", epsilon = 0.1)\n",
        "   SVR_model.fit(X_train, Y_train)\n",
        "   Y_pred = SVR_model.predict(X_test)\n",
        "   print(\"[SVM : Support Vector Machine]\")\n",
        "   print(\"accuracy : {:.3f}\".format(SVR_model.score(X_train, Y_train)))\n",
        "   rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "   print(\"RMSE : {:.3f}\".format(rmse))\n",
        "   print(SVR_model.coef_)\n",
        "   self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def NaiveBayes(self, train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    NB_model_reg = BayesianRidge(alpha_1 = 0.001, lambda_1 = 0.001)\n",
        "    NB_model_reg.fit(X_train, Y_train)\n",
        "    Y_pred = NB_model_reg.predict(X_test)\n",
        "    print(\"accuracy : {:.3f}\".format(NB_model_reg.score(X_train, Y_train)))\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"rmse :  {:.3f}\".format(rmse))\n",
        "    print(NB_model_reg.coef_)\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def MLP(self, train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    nn_reg_model = MLPRegressor(random_state = 0, alpha = 0.0001, max_iter = 2000, \n",
        "                            hidden_layer_sizes = [50, 50])\n",
        "    nn_reg_model.fit(X_train, Y_train)\n",
        "    Y_pred = nn_reg_model.predict(X_test)\n",
        "    print(\"Y predict value : \\n\", Y_pred)\n",
        "    print(\"train accuracy : {:.3f}\".format(nn_reg_model.score(X_train, Y_train)))\n",
        "    \n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"RMSE : {:.3f}\".format(rmse))\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def DNN(self,train_test_data):\n",
        "      np.random.seed(0)\n",
        "      tf.random.set_seed(0)\n",
        "\n",
        "      X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "\n",
        "      X_train2 = pd.DataFrame(X_train)\n",
        "      model = keras.models.Sequential()\n",
        "      model.add(keras.layers.Dense(64, input_dim=len(X_train2.columns), activation = \"relu\"))\n",
        "      model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
        "      model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
        "\n",
        "      #6. 모형 학습\n",
        "      model.compile(loss = \"mse\", optimizer = \"SGD\")\n",
        "      Y_pred = np.round(model.predict(X_test[:5], verbose=0), 3)\n",
        "      print(\"Y predict value \\n\", Y_pred)\n",
        "      #7. 모형 평가\n",
        "      train_score = model.evaluate(X_train, Y_train, verbose=0)\n",
        "      test_score = model.evaluate(X_test, self.Y_test, verbose=0)\n",
        "      print(\"train mse : {:.3f}\".format(train_score))\n",
        "      print(\"test mse : {:.3f}\".format(test_score))\n",
        "      self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "      #print(\"train accuracy : {:.3f}\".format(train_score[0], train_score[1]))\n",
        "      #print(\"test accuracy : {:.3f}\".format(test_score[0], test_score[1]))\n",
        "\n",
        "  def RandomForest(self,train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    model = RandomForestRegressor(random_state = 0, n_estimators = 100, max_depth = 4)\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    print(\"Y predict value : \\n\", Y_pred)\n",
        "    print(\"accracy(R2) : {:.3f}\".format(model.score(X_train, Y_train)))\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"RMSE :\", rmse)\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "\n",
        "  def Gradien(self,train_test_data):\n",
        "    X_train, X_test, Y_train, self.Y_test = self.train_test_data\n",
        "    model = GradientBoostingRegressor(random_state = 0, n_estimators = 100, max_depth = 4, \n",
        "                                   learning_rate = 0.1)\n",
        "    #5. 모형 학습 예측\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    print(\"Y predict value : \\n\", Y_pred)\n",
        "    print(\"accracy(R2) : {:.3f}\".format(model.score(X_train, Y_train)))\n",
        "    rmse = sqrt(mean_squared_error(self.Y_test, Y_pred))\n",
        "    print(\"RMSE :\", rmse)\n",
        "    self.Y_value = [Y_pred, self.Y_test]\n",
        "    return model\n"
      ]
    }
  ]
}